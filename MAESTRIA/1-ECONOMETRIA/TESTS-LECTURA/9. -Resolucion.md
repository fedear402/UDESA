# Máxima Verosimilitud
## Test de Lectura

1. Supongamos que $Z$ es $N(\mu, \sigma^2)$. Escribí la función de densidad para $\mu = 5$ y $\sigma^2 = 1$ y la función de verosimilitud para $z = 5$. ¿Cuáles son las diferencias y similitudes?

2. ¿Por qué decimos que las tres normalizaciones son equivalentes a efectos del problema de maximizar la verosimilitud?

3. ¿En qué sentido decimos que el problema de máxima verosimilitud es un problema de ingeniería reversa?

4. Si $\hat{\theta}_0$ es el estimador máximo verosímil para $\theta_0$, ¿cómo podemos construir un estimador máximo verosímil para $e^{\theta_0}$?

5. V o F. La propiedad de invarianza dice que si $\hat{\theta}_0$ es máximo verosímil para $\theta_0$, entonces $g(\hat{\theta}_0)$ es consistente para $g(\theta_0)$ para cualquier $g(\cdot)$ invertible.

6. Si $\hat{\theta}_0$ es un estimador máximo verosímil e insesgado para la varianza, mostrar que el estimador máximo verosímil para el desvío estándar es sesgado.

7. V o F (esta es complicada y tramposa): bajo los supuestos clásicos más el de normalidad de los $u_i$'s, el estimador de Mínimos Cuadrados Ordinarios es el estimador insesgado de varianza mínima (sin requerir que el estimador sea lineal, a diferencia del Teorema de Gauss Markov).